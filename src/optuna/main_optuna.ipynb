{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccff9b3c-68ff-481e-a5ec-24529b7ee093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import yaml\n",
    "import argparse\n",
    "import optuna\n",
    "import mlflow\n",
    "\n",
    "from mlflow.optuna import MlflowStorage\n",
    "from mlflow.pyspark.optuna.study import MlflowSparkStudy\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from src.model.model_factory import get_model\n",
    "from src.utils.callbacks import LogPredictionsCallback\n",
    "from src.data.optuna_snuplass_datamodule import get_datamodule\n",
    "from src.utils.get_from_overview import get_split_from_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3ef72ac-5053-4204-a0c8-92ec52ce7d57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial, base_config, model_name, tracking_uri, experiment_name):\n",
    "    # Copy config per trial\n",
    "    config = copy.deepcopy(base_config)\n",
    "    opt_cfg = config['optuna']\n",
    "\n",
    "    # Sample hyperparameters\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    config['model'][model_name]['lr'] = lr\n",
    "    trial.set_user_attr('lr', lr)\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [4, 8, 16, 32])\n",
    "    config['model'][model_name]['batch_size'] = batch_size\n",
    "    trial.set_user_attr('batch_size', batch_size)\n",
    "\n",
    "    # Set MLflow context\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=experiment_name,\n",
    "        run_name=f\"{model_name}-trial{trial.number}\",\n",
    "        tracking_uri=tracking_uri,\n",
    "        tags={'model': model_name}\n",
    "    )\n",
    "\n",
    "    # Data and model\n",
    "    datamodule = get_datamodule(config['data'])\n",
    "    model = get_model(model_name, config['model'][model_name])\n",
    "\n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=config['training']['monitor'],\n",
    "        mode=config['training']['monitor_mode'],\n",
    "        patience=config['training']['early_stopping_patience'],\n",
    "        verbose=True\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        dirpath=\"/tmp/checkpoints\",\n",
    "        monitor=config['training']['monitor'],\n",
    "        mode=config['training']['monitor_mode'],\n",
    "        save_top_k=1,\n",
    "        filename=f\"{{epoch:02d}}-{{{config['training']['monitor']}: .4f}}\"\n",
    "    )\n",
    "    log_pred = LogPredictionsCallback(**config.get('log_predictions_callback', {}))\n",
    "    pruning = PyTorchLightningPruningCallback(\n",
    "        trial,\n",
    "        monitor=config['training']['monitor'],\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        logger=mlf_logger,\n",
    "        default_root_dir=\"/tmp\",\n",
    "        max_epochs=config['training']['max_epochs'],\n",
    "        accelerator=config['training']['accelerator'],\n",
    "        devices=config['training']['devices'],\n",
    "        precision=config['training']['precision'],\n",
    "        callbacks=[early_stop, checkpoint, log_pred, pruning],\n",
    "        log_every_n_steps=10,\n",
    "        deterministic=True,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    val_metrics = trainer.validate(model, datamodule=datamodule)[0]\n",
    "    return val_metrics[opt_cfg['metric_name']]\n",
    "\n",
    "\n",
    "def main(config_path):\n",
    "    # Load config\n",
    "    with open(config_path) as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "    model_name = config['model_names'][0]\n",
    "    opt_cfg = config['optuna']\n",
    "    tracking_uri = config['logging'].get('tracking_uri', 'databricks')\n",
    "\n",
    "    # Create SparkSession once here\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "    experiment_name = f\"/Users/{username}/{model_name}\"\n",
    "    experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "    # Get train, val, holdout splits as Python lists here ONCE\n",
    "    train, val, holdout = get_split_from_overview(\n",
    "        spark,\n",
    "        config['data']['spark_catalog'],\n",
    "        config['data']['spark_schema'],\n",
    "        config['data']['train']['overview_table'],\n",
    "        config['data']['train']['id_field'],\n",
    "        require_mask=True\n",
    "    )\n",
    "\n",
    "    # Insert splits into config as plain Python data (replace any Spark references!)\n",
    "    config['data']['train_ids'] = train\n",
    "    config['data']['val_ids'] = val\n",
    "    config['data']['holdout_ids'] = holdout\n",
    "\n",
    "\n",
    "    # Setup MLflow storage\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlflow_storage = MlflowStorage(experiment_id=experiment_id)\n",
    "\n",
    "    # Create distributed study\n",
    "    study = MlflowSparkStudy(\n",
    "        study_name=f\"optuna-{model_name}\",\n",
    "        storage=mlflow_storage,\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=10)\n",
    "    )\n",
    "\n",
    "    study._directions = [opt_cfg['direction']]\n",
    "\n",
    "    # Run optimization in parallel\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, config, model_name, tracking_uri, experiment_name),\n",
    "        n_trials=opt_cfg.get('n_trials', 30),\n",
    "        n_jobs=opt_cfg.get('n_jobs', 1)\n",
    "    )\n",
    "\n",
    "    # Logger beste verdi og parametre\n",
    "    trial = study.best_trial\n",
    "    print(f\"Best trial iou: {trial.value}\")\n",
    "    print(\"Best trial params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--config', default='train.yaml')\n",
    "    args, _ = parser.parse_known_args()\n",
    "    main(args.config)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "main_optuna",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
