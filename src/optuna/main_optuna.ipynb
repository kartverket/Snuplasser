{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53db820a-e830-44d7-91b3-fa991c065e53",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install optuna mlflow lightning optuna-integration[pytorch_lightning] segmentation_models_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ccff9b3c-68ff-481e-a5ec-24529b7ee093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import yaml\n",
    "import argparse\n",
    "import optuna\n",
    "import mlflow\n",
    "from optuna.integration import PyTorchLightningPruningCallback\n",
    "from lightning.pytorch import Trainer\n",
    "from lightning.pytorch.loggers import MLFlowLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pyspark.sql import SparkSession\n",
    "from src.model.model_factory import get_model\n",
    "from src.utils.callbacks import LogPredictionsCallback\n",
    "from src.data.optuna_snuplass_datamodule import get_datamodule\n",
    "from src.utils.get_from_overview import get_split_from_overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3ef72ac-5053-4204-a0c8-92ec52ce7d57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial: optuna.Trial, config: dict, model_name: str, tracking_uri: str, experiment_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Kjører Optuna hyperparameter-tuning for en gitt modell.\n",
    "    Argumenter:\n",
    "        trial (Trial): Optuna trial\n",
    "        config (dict): Konfigurasjonen\n",
    "        model_name (str): Navnet på modellen som skal optimeres\n",
    "        tracking_uri (str): URI til MLflow-trackeren\n",
    "        experiment_name (str): Navnet på MLflow-expirementet\n",
    "    Returnerer:\n",
    "        float: Verdien til metrikken som optimiseres\n",
    "    \"\"\"\n",
    "    opt_cfg = config['optuna']\n",
    "\n",
    "    # Hyperparameter tuning\n",
    "    lr = trial.suggest_float('lr', 1e-5, 1e-2, log=True)\n",
    "    wd = trial.suggest_float('wd', 1e-5, 1e-2, log=True)\n",
    "    config['model'][model_name]['lr'] = lr\n",
    "    config['model'][model_name]['wd'] = wd\n",
    "    trial.set_user_attr('lr', lr)\n",
    "    trial.set_user_attr('wd', wd)\n",
    "\n",
    "    batch_size = trial.suggest_categorical('batch_size', [4, 8, 16, 32])\n",
    "    config['model'][model_name]['batch_size'] = batch_size\n",
    "    trial.set_user_attr('batch_size', batch_size)\n",
    "\n",
    "    # Setter opp logger\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    mlf_logger = MLFlowLogger(\n",
    "        experiment_name=experiment_name,\n",
    "        run_name=f\"{model_name}-trial{trial.number}\",\n",
    "        tracking_uri=tracking_uri,\n",
    "        tags={'model': model_name}\n",
    "    )\n",
    "\n",
    "    # Data & modell\n",
    "    datamodule = get_datamodule(config, model_name)\n",
    "    model = get_model(model_name, config['model'][model_name])\n",
    "\n",
    "    early_stop = EarlyStopping(\n",
    "        monitor=config['training']['monitor'],\n",
    "        mode=config['training']['monitor_mode'],\n",
    "        patience=config['training']['early_stopping_patience'],\n",
    "        verbose=True\n",
    "    )\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        dirpath=\"/tmp/checkpoints\",\n",
    "        monitor=config['training']['monitor'],\n",
    "        mode=config['training']['monitor_mode'],\n",
    "        save_top_k=1,\n",
    "        filename=f\"{{epoch:02d}}-{{{config['training']['monitor']}: .4f}}\"\n",
    "    )\n",
    "    log_pred = LogPredictionsCallback(**config.get('log_predictions_callback', {}))\n",
    "    pruning = PyTorchLightningPruningCallback(\n",
    "        trial,\n",
    "        monitor=config['training']['monitor'],\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        logger=mlf_logger,\n",
    "        default_root_dir=\"/tmp\",\n",
    "        max_epochs=config['training']['max_epochs'],\n",
    "        accelerator=config['training']['accelerator'],\n",
    "        devices=config['training']['devices'],\n",
    "        precision=config['training']['precision'],\n",
    "        callbacks=[early_stop, checkpoint, log_pred, pruning],\n",
    "        log_every_n_steps=10,\n",
    "        deterministic=True,\n",
    "        enable_progress_bar=False,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, datamodule=datamodule)\n",
    "    val_metrics = trainer.validate(model, datamodule=datamodule)[0]\n",
    "    return val_metrics[opt_cfg['metric_name']]\n",
    "\n",
    "\n",
    "def main(config_path: str):\n",
    "    \"\"\"\n",
    "    Kjører Optuna hyperparameter-tuning for en gitt modell.\n",
    "    Argumenter:\n",
    "        config_path: Sti til YAML-fil med konfigurasjonen\n",
    "    \"\"\"\n",
    "    # Laster inn konfigurasjonen\n",
    "    with open(config_path) as f:\n",
    "        base_config = yaml.safe_load(f)\n",
    "    config = copy.deepcopy(base_config)\n",
    "\n",
    "    model_name = config['model_names'][0]\n",
    "    opt_cfg = config['optuna']\n",
    "    tracking_uri = config['logging'].get('tracking_uri', 'databricks')\n",
    "\n",
    "    # Setter opp eksperiment\n",
    "    mlflow.set_tracking_uri(tracking_uri)\n",
    "    spark = SparkSession.builder.getOrCreate()\n",
    "    username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "    experiment_name = f\"/Users/{username}/{model_name}\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "\n",
    "    # Setter opp Optuna\n",
    "    study = optuna.create_study(\n",
    "        study_name=f\"optuna-{model_name}\",\n",
    "        direction=opt_cfg['direction'],\n",
    "        pruner=optuna.pruners.MedianPruner(n_startup_trials=3, n_warmup_steps=10)\n",
    "    )\n",
    "\n",
    "    # Kjører optimisering\n",
    "    study.optimize(\n",
    "        lambda trial: objective(trial, config, model_name, tracking_uri, experiment_name),\n",
    "        n_trials=opt_cfg.get('n_trials', 30),\n",
    "        n_jobs=opt_cfg.get('n_jobs', 1)\n",
    "    )\n",
    "\n",
    "    # Logger beste verdi og parametre\n",
    "    trial = study.best_trial\n",
    "    print(f\"Beste {opt_cfg['metric_name']}: {trial.value}\")\n",
    "    print(\"Beste parametre:\")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--config\", type=str, default=\"train.yaml\", help=\"Sti til YAML-konfigurasjon\"\n",
    "    )\n",
    "    args, _ = parser.parse_known_args()\n",
    "    main(args.config)\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "main_optuna",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
