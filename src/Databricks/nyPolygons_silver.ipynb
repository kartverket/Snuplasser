{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29639b37-6b36-4e30-9cd5-dbf75c00e7be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2b5ba7-1d3f-4e1c-bb44-d99c0dbe8f94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import min as spark_min, max as spark_max\n",
    "from pyspark.sql.types import ArrayType, DoubleType, StringType, StructType, StructField, IntegerType, LongType, FloatType\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "from sedona.spark import *\n",
    "\n",
    "import random\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "from dotenv import load_dotenv\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f2b3ea-c84c-4d5e-b25a-e7bc94c5effb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_dev = \"`land_topografisk-gdb_dev`\"\n",
    "schema_dev = \"ai2025\"\n",
    "spark.sql(f\"USE CATALOG {catalog_dev}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_dev}\")\n",
    "log_table = \"logs_processed_gdbs\"\n",
    "bronze_table = \"nypolygons_bronze\"\n",
    "silver_table = \"nyPolygons_silver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "493f7b48-2fbc-47e1-898d-b88f51eb9071",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_table_to_wkt():\n",
    "    df_bronze = spark.read.table(bronze_table).withColumn(\"geometry\", F.expr(\"ST_GeomFromWKT(geometry)\"))\n",
    "    return df_bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "260c68d1-b956-4c0c-bb69-fb7302380a1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_envelope(df:DataFrame) -> DataFrame:\n",
    "    return df.withColumn(\"envelope\", F.expr(\"ST_Envelope(geometry)\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7b6591b-4bae-4ba5-835c-6909f1f56380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def random_adjusted_bbox_centered(\n",
    "    envelope: list,\n",
    "    bbox_size: int = 128,\n",
    "    max_offset: float = 50\n",
    ") -> list:\n",
    "  \n",
    "    xmin, ymin, xmax, ymax = envelope\n",
    "    poly_width = xmax - xmin\n",
    "    poly_height = ymax - ymin\n",
    "\n",
    "\n",
    "    if poly_width > bbox_size or poly_height > bbox_size:\n",
    "        print(\"OBS: polygon er stÃ¸rre enn bbox\")\n",
    "        max_offset = 0\n",
    "\n",
    "    half_size = bbox_size / 2\n",
    "\n",
    "    center_x = (xmin + xmax) / 2 + random.uniform(-max_offset, max_offset)\n",
    "    center_y = (ymin + ymax) / 2 + random.uniform(-max_offset, max_offset)\n",
    "\n",
    "    adjusted_xmin = center_x - half_size\n",
    "    adjusted_xmax = center_x + half_size\n",
    "    adjusted_ymin = center_y - half_size\n",
    "    adjusted_ymax = center_y + half_size\n",
    "\n",
    "    bbox = [adjusted_xmin, adjusted_ymin, adjusted_xmax, adjusted_ymax]\n",
    "    bbox_str = \"_\".join(f\"{v:.6f}\" for v in bbox)\n",
    "    return bbox, bbox_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd8dcce-30da-4ad0-8921-2668f10c318a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_bbox(df: DataFrame, column_name: str) -> DataFrame:\n",
    "    df = df.withColumn(\n",
    "        \"bbox\",\n",
    "        F.expr(f\"\"\"\n",
    "        array(\n",
    "            ST_X(ST_Centroid({column_name})) - 256,\n",
    "            ST_Y(ST_Centroid({column_name})) - 256,\n",
    "            ST_X(ST_Centroid({column_name})) + 256,\n",
    "            ST_Y(ST_Centroid({column_name})) + 256\n",
    "        )\n",
    "        \"\"\")\n",
    "    )\n",
    "    \n",
    "    df = df.withColumn(\"Polygons\", F.expr(\"ST_MakeEnvelope(bbox[0], bbox[1], bbox[2], bbox[3])\")) \\\n",
    "           .withColumn(\"adjusted_struct\", adjusted_bbox_udf(F.col(\"bbox\"))) \\\n",
    "           .withColumn(\"Adjusted_bbox\", F.col(\"adjusted_struct.bbox\")) \\\n",
    "           .withColumn(\"bbox_str\", F.col(\"adjusted_struct.bbox_str\")) \\\n",
    "           .drop(column_name)  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b90ca599-6c72-4b33-8231-b06466cfc8f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_dom_url(bbox_str):\n",
    "    width, height = [512, 512]\n",
    "    return (\n",
    "        f\"https://wms.geonorge.no/skwms1/wms.hoyde-dom-nhm-25833?request=GetMap&Format=image/png&\"\n",
    "        f\"GetFeatureInfo=text/plain&CRS=EPSG:25833&Layers=NHM_DOM_25833:skyggerelieff&\"\n",
    "        f\"BBOX={bbox_str}&width={width}&height={height}\"\n",
    "    )\n",
    "\n",
    "def generate_image_url(bbox_str):\n",
    "    width, height = [512, 512]\n",
    "    return (\n",
    "        f\"https://wms.geonorge.no/skwms1/wms.nib?VERSION=1.3.0\"\n",
    "        f\"&service=WMS&request=GetMap&Format=image/png&\"\n",
    "        f\"GetFeatureInfo=text/plain&CRS=EPSG:25833&Layers=ortofoto&\"\n",
    "        f\"BBox={bbox_str}&width={width}&height={height}&TICKET=\"\n",
    "    )\n",
    "\n",
    "def dom_file_exists(id: str) -> str:\n",
    "    path = f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storredom/dom_{id}.png\"\n",
    "    return \"DOWNLOADED\" if os.path.exists(path) else \"PENDING\"\n",
    "\n",
    "def image_file_exists(id: str) -> str:\n",
    "    path = f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storreimage/image_{id}.png\"\n",
    "    return \"DOWNLOADED\" if os.path.exists(path) else \"PENDING\"\n",
    "\n",
    "def mask_file_exists(id: str) -> str:\n",
    "    path = f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storrelabel/mask_{id}.png\"\n",
    "    return \"GENERATED\" if os.path.exists(path) else \"PENDING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90f6927b-8c63-447e-8fd4-ee6637021907",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_delta_table(sdf: DataFrame):\n",
    "    \"\"\"\n",
    "    Write Spark DataFrame to Delta table.\n",
    "    Automatically updates or inserts all columns.\n",
    "    \"\"\"\n",
    "    if not spark.catalog.tableExists(silver_table):\n",
    "        sdf.write.format(\"delta\") \\\n",
    "            .option(\"mergeSchema\", \"true\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .saveAsTable(silver_table)\n",
    "    else:\n",
    "        delta_tbl = DeltaTable.forName(spark, silver_table)\n",
    "        delta_tbl.alias(\"target\") \\\n",
    "            .merge(\n",
    "                source=sdf.alias(\"source\"),\n",
    "                condition=\"target.row_hash = source.row_hash\"\n",
    "            ) \\\n",
    "            .whenMatchedUpdateAll() \\\n",
    "            .whenNotMatchedInsertAll() \\\n",
    "            .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b893be0-f502-4101-a6d7-8266d1896b95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot(df: DataFrame, column_name: str):\n",
    "    \"\"\"\n",
    "    Plot the bbox.\n",
    "    \"\"\"\n",
    "    bbox_gdf = gpd.GeoDataFrame(\n",
    "    df.toPandas(),\n",
    "    geometry=column_name,\n",
    "    crs=\"EPSG:25833\",  \n",
    "    )\n",
    "    return bbox_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5629857-d86e-443e-bc15-4c3b15257420",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def dom_path(row_hash):\n",
    "    return f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storredom/dom_{row_hash}.png\"\n",
    "\n",
    "def image_path(row_hash):\n",
    "    return f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storreimage/image_{row_hash}.png\"\n",
    "\n",
    "def mask_path(row_hash):\n",
    "    return f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storrelabel/mask_{row_hash}.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f9e2e1c-1642-4a4b-b928-ba5b0024e06e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dom_path_udf = udf(dom_path, StringType())\n",
    "image_path_udf = udf(image_path, StringType())\n",
    "mask_path_udf = udf(mask_path, StringType())\n",
    "\n",
    "dom_path_udf = udf(dom_path, StringType())\n",
    "image_path_udf = udf(image_path, StringType())\n",
    "mask_path_udf = udf(mask_path, StringType())\n",
    "\n",
    "adjusted_bbox_schema = StructType([\n",
    "    StructField(\"bbox\", ArrayType(DoubleType())),\n",
    "    StructField(\"bbox_str\", StringType())\n",
    "])\n",
    "adjusted_bbox_udf = F.udf(lambda envelope: random_adjusted_bbox_centered(envelope), adjusted_bbox_schema)\n",
    "generate_dom_url_udf = F.udf(generate_dom_url, StringType())\n",
    "generate_image_url_udf = F.udf(generate_image_url, StringType())\n",
    "dom_file_exists_udf = F.udf(dom_file_exists, StringType())\n",
    "image_file_exists_udf = F.udf(image_file_exists, StringType())\n",
    "mask_file_exists_udf = F.udf(mask_file_exists, StringType())\n",
    "\n",
    "df= read_table_to_wkt()\n",
    "df = make_envelope(df)\n",
    "df = make_bbox(df,\"envelope\")\n",
    "df = df.withColumn(\"dom_wms\", generate_dom_url_udf(\"Adjusted_bbox\")) \\\n",
    "       .withColumn(\"image_wms\", generate_image_url_udf(\"Adjusted_bbox\")) \\\n",
    "       .withColumn(\"dom_path\", dom_path_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"image_path\", image_path_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"mask_path\", mask_path_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"dom_status\", dom_file_exists_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"image_status\", image_file_exists_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"mask_status\", mask_file_exists_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"lastet_tid\", F.current_timestamp())\n",
    "gdf= plot(df, \"Polygons\")\n",
    "write_delta_table(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a4559fd-0b9d-4e0e-8a0b-e59ad121a0ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c40952f3-3831-453d-99d5-15c6bd883d55",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#spark.sql(f\"DROP TABLE IF EXISTS {silver_table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fe0ab61-cabd-43c4-bb22-8c726329a390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_retable = spark.read.table(silver_table)\n",
    "df_overview = df_retable.drop(\n",
    "    \"Shape_Length\",\n",
    "    \"Shape_Area\",\n",
    "    \"Vegtyper\",\n",
    "    \"Snuplasstype\",\n",
    "    \"Parkering\",\n",
    "    \"geometry\",\n",
    "    \"ingest_time\",\n",
    "    \"source_file\",\n",
    "    \"source_layer\",\n",
    "    \"bbox\",\n",
    "    \"Polygons\",\n",
    "    \"adjusted_struct\",\n",
    "    \"Adjusted_bbox\",\n",
    "    \"bbox_str\",\n",
    "    \"image_wms\",\n",
    "    \"dom_wms\",\n",
    "    \"lastet_tid\",\n",
    "    \"fototid\",\n",
    ")\n",
    "\n",
    "df_overview.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"polygons_status_overview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbaa0cfd-9c3b-4632-aaf0-7660d0c7bbf3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#spark.sql(f\"DROP TABLE IF EXISTS polygons_status_overview\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "nyPolygons_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
