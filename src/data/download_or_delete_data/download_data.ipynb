{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8087e0-5a62-4222-93e3-89a68ef16ba3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "14b6804f-3d41-4ce1-b005-a77cb12c2691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "from PIL import Image, ImageDraw\n",
    "import numpy as np\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "from pyspark.sql.functions import col, lit\n",
    "from delta.tables import DeltaTable\n",
    "import ast\n",
    "import geopandas as gpd\n",
    "from dotenv import load_dotenv\n",
    "from shapely import wkb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7381f9bc-9c31-4633-95ea-be2fff2e6091",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [512, 512]\n",
    "catalog_dev = \"`land_topografisk-gdb_dev`\"\n",
    "schema_dev = \"ai2025\"\n",
    "spark.sql(f\"USE CATALOG {catalog_dev}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_dev}\")\n",
    "silver_table = \"polygons_silver\"\n",
    "endepunkt_table = \"endepunkt_silver\"\n",
    "hospital_table = \"hospitals_silver\"\n",
    "helicopter_table = \"helicopters_silver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1d409cb-014e-4beb-960c-e8b3d4907b7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "brukerid = os.getenv(\"GEONORGE_BRUKERID\")\n",
    "passord = os.getenv(\"GEONORGE_PASSORD\")\n",
    "\n",
    "def get_token():\n",
    "    \"\"\"\n",
    "    Henter en token fra Geonorge og returnerer den.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        f\"https://baat.geonorge.no/skbaatts/req?brukerid={brukerid}\"\n",
    "        f\"&passord={passord}&tjenesteid=wms.nib&retformat=s\"\n",
    "    )\n",
    "    raw_token = requests.get(url).text.strip(\"`\")\n",
    "    return raw_token\n",
    "\n",
    "token = get_token()\n",
    "token_start_time = time.time()\n",
    "token_lifetime = 55 * 60  # sekunder\n",
    "\n",
    "def refresh_token_if_needed():\n",
    "    \"\"\"\n",
    "    Henter en ny token hvis den er utl√∏pt.\n",
    "    \"\"\"\n",
    "    global token, token_start_time\n",
    "    if time.time() - token_start_time > token_lifetime:\n",
    "        print(\"üîÑ Fornyer token...\")\n",
    "        token = get_token()\n",
    "        token_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5acf360f-326d-4445-bacb-e52387db4133",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_binary_mask(geom, out_path, bbox, width=512, height=512):\n",
    "    \"\"\"\n",
    "    Lager en bin√¶r maske basert p√• en geometri (Polygon eller MultiPolygon)\n",
    "    og lagrer den som PNG. BBOX m√• alltid oppgis, og tolkes som koordinatramme.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not isinstance(bbox, (list, tuple)) or len(bbox) != 4:\n",
    "            print(f\"‚ùå Ugyldig bbox: {bbox}\")\n",
    "            return False\n",
    "\n",
    "        minx, miny, maxx, maxy = bbox\n",
    "        assert maxx > minx and maxy > miny\n",
    "\n",
    "        mask = Image.new(\"L\", (width, height), 0)\n",
    "        draw = ImageDraw.Draw(mask)\n",
    "\n",
    "        def world_to_pixel(x, y):\n",
    "            px = int((x - minx) / (maxx - minx) * width)\n",
    "            py = int((maxy - y) / (maxy - miny) * height)\n",
    "            return (px, py)\n",
    "\n",
    "        def draw_single_polygon(polygon):\n",
    "            exterior = [world_to_pixel(x, y) for x, y in polygon.exterior.coords]\n",
    "            draw.polygon(exterior, outline=255, fill=255)\n",
    "        # H√•ndter geometri\n",
    "        if isinstance(geom, Polygon):\n",
    "            draw_single_polygon(geom)\n",
    "        elif isinstance(geom, MultiPolygon):\n",
    "            for poly in geom.geoms:\n",
    "                draw_single_polygon(poly)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Ukjent geometritype: {type(geom)}\")\n",
    "            return False\n",
    "\n",
    "        mask.save(out_path)\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Feil ved maskegenerering: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52ceb975-f44a-4f6c-afbf-f5ef863b2d27",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def parse_bbox(value):\n",
    "    if value is None or (isinstance(value, float) and np.isnan(value)):\n",
    "        raise ValueError(\"Verdi er tom eller NaN\")\n",
    "    if isinstance(value, str):\n",
    "        value = ast.literal_eval(value)\n",
    "    if isinstance(value, (list, tuple, np.ndarray)) and len(value) == 4:\n",
    "        return tuple(float(v) for v in value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30cdc891-9ec9-48f8-ac36-7694fb29d41c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def download_image(url: str, out_path: str, retries: int = 3, backoff: float = 2.0) -> bool:\n",
    "    \"\"\"\n",
    "    Pr√∏ver √• laste ned et bilde fra en URL og lagrer det lokalt. \n",
    "    \"\"\"\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            r = requests.get(url, timeout=30)\n",
    "            if r.status_code == 200:\n",
    "                with open(out_path, \"wb\") as f:\n",
    "                    f.write(r.content)\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è Nedlasting feilet (status {r.status_code}) p√• fors√∏k {attempt}\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Feil ved nedlasting p√• fors√∏k {attempt}: {e}\")\n",
    "        \n",
    "        # Pr√∏ver p√• nytt ved feil, med eksponentiell backoff\n",
    "        if attempt < retries:\n",
    "            sleep_time = backoff * attempt  # eksponentiell ventetid\n",
    "            time.sleep(sleep_time)\n",
    "\n",
    "    print(f\"‚ùå Alle {retries} fors√∏k mislyktes for {url}\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8da8124c-52e4-45ef-8fab-379e2b7bf3c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def download_pending_images(table: str, id_col: str, image_output_dir: str, dom_output_dir: str = None):\n",
    "    \"\"\"\n",
    "    Laster ned alle bilder som er markedert som 'PENDING' i s√∏lvtabellen og setter dem som 'DOWNLOADED'.\n",
    "    \"\"\"\n",
    "    df = spark.read.table(table)\n",
    "    cols = df.columns\n",
    "\n",
    "    # Trenger ikke √• ha b√•de dom_status og image_status\n",
    "    conditions = []\n",
    "    if \"dom_status\" in cols:\n",
    "        conditions.append(\"dom_status = 'PENDING'\")\n",
    "    if \"image_status\" in cols:\n",
    "        conditions.append(\"image_status = 'PENDING'\")\n",
    "\n",
    "    filter_expr = \" OR \".join(conditions)\n",
    "    df_pending = df.filter(filter_expr).toPandas()\n",
    "\n",
    "    delta_tbl = DeltaTable.forName(spark, table)\n",
    "\n",
    "    for _, row in df_pending.iterrows():\n",
    "        id_value = row[id_col]\n",
    "\n",
    "        # Last ned dom-bilder\n",
    "        if dom_output_dir and \"dom_status\" in cols and row.get(\"dom_status\") == \"PENDING\":\n",
    "            dom_out = f\"{dom_output_dir}/dom_{id_value}.png\"\n",
    "            if download_image(row[\"dom_wms\"], dom_out):\n",
    "                delta_tbl.update(\n",
    "                    condition=f\"{id_col} = '{id_value}'\",\n",
    "                    set={\"dom_status\": lit(\"DOWNLOADED\")}\n",
    "                )\n",
    "\n",
    "        # Last ned bilder\n",
    "        if \"image_status\" in cols and row.get(\"image_status\") == \"PENDING\":\n",
    "            refresh_token_if_needed()\n",
    "            base = row[\"image_wms\"]\n",
    "            image_url = f\"{base}&TICKET={token}\" if isinstance(base, str) and base.startswith(\"http\") else base\n",
    "            image_out = f\"{image_output_dir}/image_{id_value}.png\"\n",
    "\n",
    "            if download_image(image_url, image_out):\n",
    "                delta_tbl.update(\n",
    "                    condition=f\"{id_col} = '{id_value}'\",\n",
    "                    set={\"image_status\": lit(\"DOWNLOADED\")}\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3c89d2ae-9cd9-446d-b24d-1f7535a521cd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def download_pending_labels(table: str, id_col: str, mask_output_dir: str):\n",
    "    \"\"\"\n",
    "    Genererer labels for alle masker som er markedert som 'PENDING' i s√∏lvtabellen og setter dem som 'GENERATED'.\n",
    "    \"\"\"\n",
    "    df_pending = spark.read.table(table) \\\n",
    "    .filter(\"mask_status = 'PENDING'\") \\\n",
    "    .toPandas()\n",
    "    df_pending[\"geometry\"] = df_pending[\"geometry\"].apply(lambda x: wkb.loads(bytes(x)) if x is not None else None)\n",
    "    gdf = gpd.GeoDataFrame(df_pending, geometry=\"geometry\", crs=\"EPSG:25833\")\n",
    "    for _, row in gdf.iterrows():\n",
    "        id_value = row[id_col]\n",
    "        filename = f\"{id_value}.png\"\n",
    "        out_path = f\"{mask_output_dir}/mask_{filename}\"\n",
    "\n",
    "        # Pr√∏v f√∏rst Adjusted_bbox, s√• fallback til bbox\n",
    "        try:\n",
    "            bbox = None\n",
    "            if \"Adjusted_bbox\" in row and row[\"Adjusted_bbox\"] is not None:\n",
    "                bbox = parse_bbox(row[\"Adjusted_bbox\"])\n",
    "            elif \"bbox\" in row and row[\"bbox\"] is not None:\n",
    "                bbox = parse_bbox(row[\"bbox\"])\n",
    "            else:\n",
    "                print(f\"‚ùå Mangler gyldig bbox for {id_value}\")\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Feil ved parsing av bbox for {id_value}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Generer bin√¶rmaske\n",
    "        success = generate_binary_mask(row[\"geometry\"], out_path, bbox)\n",
    "        if success:\n",
    "            DeltaTable.forName(spark, table).update(\n",
    "                condition=f\"{id_col} = '{id_value}'\",\n",
    "                set={\"mask_status\": lit(\"GENERATED\")}\n",
    "            )\n",
    "            print(f\"‚úÖ Maske generert for {id_value}\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Maske-generering feilet for {id_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e808a177-9881-4b26-a335-0c8339128d05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "snuplass_dom_output_dir = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storredom/\"\n",
    "snuplass_image_output_dir = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storreimage/\"\n",
    "snuplass_mask_dir = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storrelabel/\"\n",
    "os.makedirs(snuplass_dom_output_dir, exist_ok=True)\n",
    "os.makedirs(snuplass_image_output_dir, exist_ok=True)\n",
    "os.makedirs(snuplass_mask_dir, exist_ok=True)\n",
    "\n",
    "download_pending_images(silver_table, \"row_hash\", snuplass_image_output_dir, snuplass_dom_output_dir)\n",
    "download_pending_labels(silver_table, \"row_hash\", snuplass_mask_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68cb8e91-6504-478a-9579-6bfe22e41e80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "endepunkt_dom_output_dir = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storreendepunkt_dom/\"\n",
    "endepunkt_image_output_dir = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storreendepunkt_images/\"\n",
    "os.makedirs(endepunkt_dom_output_dir, exist_ok=True)\n",
    "os.makedirs(endepunkt_image_output_dir, exist_ok=True)\n",
    "\n",
    "download_pending_images(endepunkt_table, \"nodeid\", endepunkt_image_output_dir, endepunkt_dom_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "966b4eb0-871e-4cce-a6bc-dffaae38149d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "hospital_image_output_dir = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/hospital_images/\"\n",
    "os.makedirs(hospital_image_output_dir, exist_ok=True)\n",
    "\n",
    "download_pending_images(hospital_table, \"lokalid\", image_output_dir=hospital_image_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b0314c5-fb18-4e93-ad7b-f9cc2cde4aaf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "helicopter_image_output_dir = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/helicopter_images/\"\n",
    "helicopter_mask_dir = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/helicopter_labels/\"\n",
    "os.makedirs(helicopter_image_output_dir, exist_ok=True)\n",
    "os.makedirs(helicopter_mask_dir, exist_ok=True)\n",
    "\n",
    "download_pending_images(helicopter_table, \"lokalid\", image_output_dir=helicopter_image_output_dir)\n",
    "download_pending_labels(helicopter_table, \"lokalid\", mask_output_dir=helicopter_mask_dir)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "download_data",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
