{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29639b37-6b36-4e30-9cd5-dbf75c00e7be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0a2b5ba7-1d3f-4e1c-bb44-d99c0dbe8f94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import min as spark_min, max as spark_max\n",
    "from pyspark.sql.types import ArrayType, DoubleType, StringType, StructType, StructField, IntegerType, LongType, FloatType, TimestampType, DateType\n",
    "\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "from sedona.spark import *\n",
    "\n",
    "import random\n",
    "import geopandas as gpd\n",
    "from pathlib import Path\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "import re\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92f2b3ea-c84c-4d5e-b25a-e7bc94c5effb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_dev = \"`land_topografisk-gdb_dev`\"\n",
    "schema_dev = \"ai2025\"\n",
    "spark.sql(f\"USE CATALOG {catalog_dev}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_dev}\")\n",
    "bronze_table = \"polygons_bronze\"\n",
    "silver_table = \"polygons_silver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "493f7b48-2fbc-47e1-898d-b88f51eb9071",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_table_to_wkt():\n",
    "    df_bronze = spark.read.table(bronze_table).withColumn(\"geometry\", F.expr(\"ST_GeomFromWKT(geometry)\"))\n",
    "    return df_bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "260c68d1-b956-4c0c-bb69-fb7302380a1b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_envelope(df:DataFrame) -> DataFrame:\n",
    "    return df.withColumn(\"envelope\", F.expr(\"ST_Envelope(geometry)\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7b6591b-4bae-4ba5-835c-6909f1f56380",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def random_adjusted_bbox_centered(\n",
    "    envelope: list,\n",
    "    bbox_size: int = 128,\n",
    "    max_offset: float = 50\n",
    ") -> list:\n",
    "  \n",
    "    xmin, ymin, xmax, ymax = envelope\n",
    "    poly_width = xmax - xmin\n",
    "    poly_height = ymax - ymin\n",
    "\n",
    "\n",
    "    if poly_width > bbox_size or poly_height > bbox_size:\n",
    "        print(\"OBS: polygon er stÃ¸rre enn bbox\")\n",
    "        max_offset = 0\n",
    "\n",
    "    half_size = bbox_size / 2\n",
    "\n",
    "    center_x = (xmin + xmax) / 2 + random.uniform(-max_offset, max_offset)\n",
    "    center_y = (ymin + ymax) / 2 + random.uniform(-max_offset, max_offset)\n",
    "\n",
    "    adjusted_xmin = center_x - half_size\n",
    "    adjusted_xmax = center_x + half_size\n",
    "    adjusted_ymin = center_y - half_size\n",
    "    adjusted_ymax = center_y + half_size\n",
    "\n",
    "    bbox = [adjusted_xmin, adjusted_ymin, adjusted_xmax, adjusted_ymax]\n",
    "    bbox_str = \"_\".join(f\"{v:.6f}\" for v in bbox)\n",
    "    return bbox, bbox_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cfd8dcce-30da-4ad0-8921-2668f10c318a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_bbox(df: DataFrame, column_name: str) -> DataFrame:\n",
    "    df = df.withColumn(\n",
    "        \"bbox\",\n",
    "        F.expr(f\"\"\"\n",
    "        array(\n",
    "            ST_X(ST_Centroid({column_name})) - 256,\n",
    "            ST_Y(ST_Centroid({column_name})) - 256,\n",
    "            ST_X(ST_Centroid({column_name})) + 256,\n",
    "            ST_Y(ST_Centroid({column_name})) + 256\n",
    "        )\n",
    "        \"\"\")\n",
    "    )\n",
    "    \n",
    "    df = df.withColumn(\"Polygons\", F.expr(\"ST_MakeEnvelope(bbox[0], bbox[1], bbox[2], bbox[3])\")) \\\n",
    "           .withColumn(\"adjusted_struct\", adjusted_bbox_udf(F.col(\"bbox\"))) \\\n",
    "           .withColumn(\"Adjusted_bbox\", F.col(\"adjusted_struct.bbox\")) \\\n",
    "           .withColumn(\"bbox_str\", F.col(\"adjusted_struct.bbox_str\")) \\\n",
    "           .drop(column_name)  \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b90ca599-6c72-4b33-8231-b06466cfc8f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_dom_url(bbox_str):\n",
    "    width, height = [512, 512]\n",
    "    return (\n",
    "        f\"https://wms.geonorge.no/skwms1/wms.hoyde-dom-nhm-25833?request=GetMap&Format=image/png&\"\n",
    "        f\"GetFeatureInfo=text/plain&CRS=EPSG:25833&Layers=NHM_DOM_25833:skyggerelieff&\"\n",
    "        f\"BBOX={bbox_str}&width={width}&height={height}\"\n",
    "    )\n",
    "\n",
    "def generate_image_url(bbox_str):\n",
    "    width, height = [512, 512]\n",
    "    return (\n",
    "        f\"https://wms.geonorge.no/skwms1/wms.nib?VERSION=1.3.0\"\n",
    "        f\"&service=WMS&request=GetMap&Format=image/png&\"\n",
    "        f\"GetFeatureInfo=text/plain&CRS=EPSG:25833&Layers=ortofoto&\"\n",
    "        f\"BBox={bbox_str}&width={width}&height={height}&TICKET=\"\n",
    "    )\n",
    "\n",
    "def dom_file_exists(id: str) -> str:\n",
    "    path = f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storredom/dom_{id}.png\"\n",
    "    return \"DOWNLOADED\" if os.path.exists(path) else \"PENDING\"\n",
    "\n",
    "def image_file_exists(id: str) -> str:\n",
    "    path = f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storreimage/image_{id}.png\"\n",
    "    return \"DOWNLOADED\" if os.path.exists(path) else \"PENDING\"\n",
    "\n",
    "def mask_file_exists(id: str) -> str:\n",
    "    path = f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/storrelabel/mask_{id}.png\"\n",
    "    return \"GENERATED\" if os.path.exists(path) else \"PENDING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4d8b387-ff6b-42db-8a04-934f572998f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "BRUKERID = os.getenv(\"GEONORGE_BRUKERID\")\n",
    "PASSORD  = os.getenv(\"GEONORGE_PASSORD\")\n",
    "\n",
    "def get_token():\n",
    "    url = (\n",
    "        f\"https://baat.geonorge.no/skbaatts/req?brukerid={BRUKERID}\"\n",
    "        f\"&passord={PASSORD}&tjenesteid=wms.nib&retformat=s\"\n",
    "    )\n",
    "    raw_token = requests.get(url).text.strip(\"`\")\n",
    "    return raw_token\n",
    "\n",
    "token = get_token()\n",
    "token_start_time = time.time()\n",
    "token_lifetime = 55 * 60  # sekunder\n",
    "\n",
    "def refresh_token_if_needed():\n",
    "    global token, token_start_time\n",
    "    if time.time() - token_start_time > token_lifetime:\n",
    "        print(\"ðŸ”„ Fornyer token...\")\n",
    "        token = get_token()\n",
    "        token_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ce9b0ec-c757-41aa-9582-f729355f270d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_fotodato(bbox: str, token: str):\n",
    "    url = f\"https://wms.geonorge.no/skwms1/wms.nib?SERVICE=WMS&VERSION=1.3.0&REQUEST=GetFeatureInfo&CRS=EPSG:25833&BBOX={bbox}&WIDTH=512&HEIGHT=512&LAYERS=ortofoto&QUERY_LAYERS=ortofoto&INFO_FORMAT=text/html&I=256&J=256&TICKET={token}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    \n",
    "    table = soup.find(\"table\")\n",
    "    field_value = None\n",
    "    \n",
    "    if table:\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) >= 2 and cells[0].text.strip() == \"Fotodato\":\n",
    "                field_value = cells[1].text.strip()\n",
    "                field_value = datetime.strptime(field_value, \"%d.%m.%Y\").date()\n",
    "                return field_value\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9d01493-d680-453c-bc23-1c5df41e8549",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_ortofoto_date(df, token: str):\n",
    "\n",
    "    \"\"\"\n",
    "    Add the ortofoto date to the dataframe based on bbox.\n",
    "    Returns a new DataFrame with the 'fototid' column added.\n",
    "    \"\"\"\n",
    "\n",
    "    # Select only relevant columns for processing\n",
    "    sample_rows = df.select(\"row_hash\", \"bbox_str\").collect()\n",
    "\n",
    "    # Fetch fotodato values from WMS\n",
    "    bbox_date_pairs = [\n",
    "        (row[\"row_hash\"], get_fotodato(row[\"bbox_str\"].replace('_', ','), token))\n",
    "        for row in sample_rows\n",
    "    ]\n",
    "\n",
    "    # Schema for intermediate DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"row_hash\", StringType(), True),\n",
    "        StructField(\"fototid\", DateType(), True)  # Use StringType if needed\n",
    "    ])\n",
    "\n",
    "    # Create small lookup DataFrame\n",
    "    bbox_date_df = spark.createDataFrame(bbox_date_pairs, schema)\n",
    "\n",
    "    # Join back on row_hash\n",
    "    df_with_date = df.join(bbox_date_df, on=\"row_hash\", how=\"left\")\n",
    "\n",
    "    return df_with_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90f6927b-8c63-447e-8fd4-ee6637021907",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_delta_table(sdf: DataFrame):\n",
    "    \"\"\"\n",
    "    Write Spark DataFrame to Delta table.\n",
    "    Automatically updates or inserts all columns.\n",
    "    \"\"\"\n",
    "    if not spark.catalog.tableExists(silver_table):\n",
    "        sdf.write.format(\"delta\") \\\n",
    "            .option(\"mergeSchema\", \"true\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .saveAsTable(silver_table)\n",
    "    else:\n",
    "        delta_tbl = DeltaTable.forName(spark, silver_table)\n",
    "        delta_tbl.alias(\"target\") \\\n",
    "            .merge(\n",
    "                source=sdf.alias(\"source\"),\n",
    "                condition=\"target.row_hash = source.row_hash\"\n",
    "            ) \\\n",
    "            .whenMatchedUpdateAll() \\\n",
    "            .whenNotMatchedInsertAll() \\\n",
    "            .execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b893be0-f502-4101-a6d7-8266d1896b95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def plot(df: DataFrame, column_name: str):\n",
    "    \"\"\"\n",
    "    Plot the bbox.\n",
    "    \"\"\"\n",
    "    bbox_gdf = gpd.GeoDataFrame(\n",
    "    df.toPandas(),\n",
    "    geometry=column_name,\n",
    "    crs=\"EPSG:25833\",  \n",
    "    )\n",
    "    return bbox_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f9e2e1c-1642-4a4b-b928-ba5b0024e06e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adjusted_bbox_schema = StructType([\n",
    "    StructField(\"bbox\", ArrayType(DoubleType())),\n",
    "    StructField(\"bbox_str\", StringType())\n",
    "])\n",
    "adjusted_bbox_udf = F.udf(lambda envelope: random_adjusted_bbox_centered(envelope), adjusted_bbox_schema)\n",
    "generate_dom_url_udf = F.udf(generate_dom_url, StringType())\n",
    "generate_image_url_udf = F.udf(generate_image_url, StringType())\n",
    "dom_file_exists_udf = F.udf(dom_file_exists, StringType())\n",
    "image_file_exists_udf = F.udf(image_file_exists, StringType())\n",
    "mask_file_exists_udf = F.udf(mask_file_exists, StringType())\n",
    "\n",
    "BASE_PATH = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER\"\n",
    " \n",
    "SUBDIR = {\n",
    "    \"image\": \"storreimage\",\n",
    "    \"dom\":   \"storredom\",\n",
    "    \"mask\":  \"storrelabel\"  \n",
    "}\n",
    "\n",
    "df= read_table_to_wkt()\n",
    "df = make_envelope(df)\n",
    "df = make_bbox(df,\"envelope\")\n",
    "\n",
    "for dt in [\"image\", \"dom\", \"mask\"]:\n",
    "    sub = SUBDIR[dt]\n",
    "    df = df.withColumn(\n",
    "        f\"{dt}_path\",\n",
    "        F.concat(\n",
    "            F.lit(f\"{BASE_PATH}/{sub}/{dt}_\"),\n",
    "            F.col(\"row_hash\"),\n",
    "            F.lit(\".png\")\n",
    "        )\n",
    "    )\n",
    "df = df.withColumn(\"dom_wms\", generate_dom_url_udf(\"Adjusted_bbox\")) \\\n",
    "       .withColumn(\"image_wms\", generate_image_url_udf(\"Adjusted_bbox\")) \\\n",
    "       .withColumn(\"dom_status\", dom_file_exists_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"image_status\", image_file_exists_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"mask_status\", mask_file_exists_udf(\"row_hash\")) \\\n",
    "       .withColumn(\"lastet_tid\", F.current_timestamp())\n",
    "df = add_ortofoto_date(df, token)\n",
    "\n",
    "gdf= plot(df, \"Polygons\")\n",
    "write_delta_table(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a4559fd-0b9d-4e0e-8a0b-e59ad121a0ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7fe0ab61-cabd-43c4-bb22-8c726329a390",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_retable = spark.read.table(silver_table)\n",
    "df_overview = df_retable.drop(\n",
    "    \"Shape_Length\",\n",
    "    \"Shape_Area\",\n",
    "    \"Vegtyper\",\n",
    "    \"Snuplasstype\",\n",
    "    \"Parkering\",\n",
    "    \"geometry\",\n",
    "    \"ingest_time\",\n",
    "    \"source_file\",\n",
    "    \"source_layer\",\n",
    "    \"bbox\",\n",
    "    \"Polygons\",\n",
    "    \"adjusted_struct\",\n",
    "    \"Adjusted_bbox\",\n",
    "    \"bbox_str\",\n",
    "    \"image_wms\",\n",
    "    \"dom_wms\",\n",
    "    \"lastet_tid\",\n",
    "    \"fototid\",\n",
    ")\n",
    "\n",
    "df_overview.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\", \"true\") \\\n",
    "    .saveAsTable(\"polygons_status_overview\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "polygons_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
