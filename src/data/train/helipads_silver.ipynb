{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fae414af-aa12-4f87-ac4c-c30924131787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    BinaryType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DateType,\n",
    ")\n",
    "from delta.tables import DeltaTable\n",
    "from sedona.spark import *\n",
    "from shapely import wkb\n",
    "from shapely.ops import unary_union\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ebd42cb-53ce-4e88-918b-b2c60e4523d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_dev = \"`land_auto-gen-kart_dev`\"\n",
    "schema_dev = \"dl_bildesegmentering\"\n",
    "spark.sql(f\"USE CATALOG {catalog_dev}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_dev}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_dev}\")\n",
    "bronze_table = \"helipads_bronze\"\n",
    "silver_table = \"helipads_silver\"\n",
    "\n",
    "BASE_PATH = \"/Volumes/land_auto-gen-kart_dev/external_dev/static_data/DL_bildesegmentering\"\n",
    "SUBDIR = {\"image\": \"helipad_images\", \"mask\": \"helipad_labels\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a7d9d1-5c7e-4209-a041-ca79e6378531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {silver_table} (\n",
    "    row_hash STRING,\n",
    "    lokalids ARRAY<STRING>,\n",
    "    geometry BINARY,\n",
    "    bbox ARRAY<DOUBLE>,\n",
    "    Polygons BINARY,\n",
    "    adjusted_struct STRUCT<bbox: ARRAY<DOUBLE>, bbox_str: STRING>,\n",
    "    Adjusted_bbox ARRAY<DOUBLE>,\n",
    "    bbox_str STRING,\n",
    "    image_path STRING,\n",
    "    mask_path STRING,\n",
    "    image_wms STRING,\n",
    "    image_status STRING,\n",
    "    mask_status STRING,\n",
    "    type STRING,\n",
    "    ingest_time TIMESTAMP,\n",
    "    load_time TIMESTAMP,\n",
    "    photo_time TIMESTAMP\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "034fb654-9c05-4754-af38-fc32b6dbad04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_table_to_wkt():\n",
    "    \"\"\"\n",
    "    Leser polygonene fra bronsetabellen og returnerer dem som en GeoDataFrame med WKT geometri.\n",
    "    \"\"\"\n",
    "    df_bronze = spark.read.table(bronze_table).withColumn(\n",
    "        \"geometry\", F.expr(\"ST_GeomFromWKB(geometry)\")\n",
    "    )\n",
    "    df = (\n",
    "        df_bronze.withColumn(\"_geom_srid\", F.expr(\"ST_SetSRID(geometry, 4326)\"))\n",
    "        .withColumn(\n",
    "            \"geometry\", F.expr(\"ST_Force2D(ST_Transform(_geom_srid, 'EPSG:25833'))\")\n",
    "        )\n",
    "        .select(\"lokalid\", \"geometry\", \"ingest_time\", \"oppdateringsdato\")\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "541cacc0-601d-406d-b9f1-b1e7bf9bc152",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_envelope(df: DataFrame, column_name: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Lager en minimal boks rundt polygonene.\n",
    "    \"\"\"\n",
    "    return df.withColumn(\"envelope\", F.expr(f\"ST_Envelope({column_name})\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12fca104-5f0c-4005-ae40-64f86c5abb89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def random_adjusted_bbox_centered(\n",
    "    envelope: list, bbox_size: int = 128, max_offset: float = 20\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Genererer en tilfeldig justert boks rundt polygonen med en maksimal avstand fra sentrum.\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = envelope\n",
    "    poly_width = xmax - xmin\n",
    "    poly_height = ymax - ymin\n",
    "\n",
    "    if poly_width > bbox_size or poly_height > bbox_size:\n",
    "        print(\"OBS: polygon er stÃ¸rre enn bbox\")\n",
    "        max_offset = 0\n",
    "\n",
    "    half_size = bbox_size / 2\n",
    "\n",
    "    center_x = (xmin + xmax) / 2 + random.uniform(-max_offset, max_offset)\n",
    "    center_y = (ymin + ymax) / 2 + random.uniform(-max_offset, max_offset)\n",
    "\n",
    "    adjusted_xmin = center_x - half_size\n",
    "    adjusted_xmax = center_x + half_size\n",
    "    adjusted_ymin = center_y - half_size\n",
    "    adjusted_ymax = center_y + half_size\n",
    "\n",
    "    bbox = [adjusted_xmin, adjusted_ymin, adjusted_xmax, adjusted_ymax]\n",
    "    bbox_str = \",\".join(f\"{v:.6f}\" for v in bbox)\n",
    "    return bbox, bbox_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcff5e74-7ac1-4da1-9a11-765f7a540cc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def envelope_to_bboxes(df: DataFrame, tile_width=128, tile_height=128) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Tar inn envelope og returnerer Ã©n bbox med gitt stÃ¸rrelse,\n",
    "    sentrert pÃ¥ envelope.\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        df.withColumn(\"xmin\", F.expr(\"ST_XMin(envelope)\"))\n",
    "        .withColumn(\"ymin\", F.expr(\"ST_YMin(envelope)\"))\n",
    "        .withColumn(\"xmax\", F.expr(\"ST_XMax(envelope)\"))\n",
    "        .withColumn(\"ymax\", F.expr(\"ST_YMax(envelope)\"))\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\"x_center\", (F.col(\"xmin\") + F.col(\"xmax\")) / 2.0).withColumn(\n",
    "        \"y_center\", (F.col(\"ymin\") + F.col(\"ymax\")) / 2.0\n",
    "    )\n",
    "\n",
    "    df = df.withColumn(\"x\", F.col(\"x_center\") - F.lit(tile_width / 2.0)).withColumn(\n",
    "        \"y\", F.col(\"y_center\") - F.lit(tile_height / 2.0)\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        df.withColumn(\n",
    "            \"tile\",\n",
    "            F.expr(\n",
    "                f\"ST_PolygonFromEnvelope(x, y, x + {tile_width}, y + {tile_height})\"\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\"bbox\", F.expr(f\"array(x, y, x + {tile_width}, y + {tile_height})\"))\n",
    "        .withColumn(\"bbox_str\", F.concat_ws(\",\", F.col(\"bbox\")))\n",
    "    )\n",
    "\n",
    "    drop_cols = [\n",
    "        \"xmin\",\n",
    "        \"ymin\",\n",
    "        \"xmax\",\n",
    "        \"ymax\",\n",
    "        \"x_center\",\n",
    "        \"y_center\",\n",
    "        \"x\",\n",
    "        \"y\",\n",
    "        \"tile\",\n",
    "    ]\n",
    "    for c in drop_cols:\n",
    "        if c in df.columns:\n",
    "            df = df.drop(c)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8d43359-59af-4a04-a67b-48f01f5bc60c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_geometry_columns(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Legger til kolonner for boks og justert boks.\n",
    "    \"\"\"\n",
    "    df = (\n",
    "        df.withColumn(\n",
    "            \"Polygons\", F.expr(\"ST_MakeEnvelope(bbox[0], bbox[1], bbox[2], bbox[3])\")\n",
    "        )\n",
    "        .withColumn(\"adjusted_struct\", adjusted_bbox_udf(F.col(\"bbox\")))\n",
    "        .withColumn(\"Adjusted_bbox\", F.col(\"adjusted_struct.bbox\"))\n",
    "        .withColumn(\"bbox_str\", F.col(\"adjusted_struct.bbox_str\"))\n",
    "        .drop(\"envelope\")\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13f94661-9628-453d-b331-dd560363e836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_image_url(bbox_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Genererer en URL for image-bilde basert pÃ¥ bbox_str.\n",
    "    \"\"\"\n",
    "    width, height = [512, 512]\n",
    "    return (\n",
    "        f\"https://wms.geonorge.no/skwms1/wms.nib?VERSION=1.3.0\"\n",
    "        f\"&service=WMS&request=GetMap&Format=image/png&\"\n",
    "        f\"GetFeatureInfo=text/plain&CRS=EPSG:25833&Layers=ortofoto&\"\n",
    "        f\"BBox={bbox_str}&width={width}&height={height}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def image_file_exists(id: str) -> str:\n",
    "    \"\"\"\n",
    "    Sjekker om bildet med gitt ID er lastet ned.\n",
    "    \"\"\"\n",
    "    path = f\"/Volumes/land_auto-gen-kart_dev/external_dev/static_data/DL_bildesegmentering/helipad_images/image_{id}.png\"\n",
    "    return \"DOWNLOADED\" if os.path.exists(path) else \"PENDING\"\n",
    "\n",
    "\n",
    "def mask_file_exists(id: str) -> str:\n",
    "    \"\"\"\n",
    "    Sjekker om masken med gitt ID er generert.\n",
    "    \"\"\"\n",
    "    path = f\"/Volumes/land_auto-gen-kart_dev/external_dev/static_data/DL_bildesegmentering/helipad_labels/mask_{id}.png\"\n",
    "    return \"GENERATED\" if os.path.exists(path) else \"PENDING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad68254d-ce96-405f-a054-14da16b43503",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "BRUKERID = os.getenv(\"GEONORGE_BRUKERID\")\n",
    "PASSORD = os.getenv(\"GEONORGE_PASSORD\")\n",
    "\n",
    "\n",
    "def get_token():\n",
    "    \"\"\"\n",
    "    Henter token fra GeoNorge og returnerer det.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        f\"https://baat.geonorge.no/skbaatts/req?brukerid={BRUKERID}\"\n",
    "        f\"&passord={PASSORD}&tjenesteid=wms.nib&retformat=s\"\n",
    "    )\n",
    "    raw_token = requests.get(url).text.strip(\"`\")\n",
    "    return raw_token\n",
    "\n",
    "\n",
    "token = get_token()\n",
    "token_start_time = time.time()\n",
    "token_lifetime = 55 * 60\n",
    "\n",
    "\n",
    "def refresh_token_if_needed():\n",
    "    \"\"\"\n",
    "    Henter ny token om den gamle er utlÃ¸pt.\n",
    "    \"\"\"\n",
    "    global token, token_start_time\n",
    "    if time.time() - token_start_time > token_lifetime:\n",
    "        print(\"ðŸ”„ Fornyer token...\")\n",
    "        token = get_token()\n",
    "        token_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f9c9114-4a3a-449a-8cc9-a451b92a4032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_fotodato(bbox: str, token: str, max_retries=10):\n",
    "    \"\"\"\n",
    "    Henter fotodato for en bbox.\n",
    "    \"\"\"\n",
    "    url = f\"https://wms.geonorge.no/skwms1/wms.nib?SERVICE=WMS&VERSION=1.3.0&REQUEST=GetFeatureInfo&CRS=EPSG:25833&BBOX={bbox}&WIDTH=512&HEIGHT=512&LAYERS=ortofoto&QUERY_LAYERS=ortofoto&INFO_FORMAT=text/html&I=256&J=256&TICKET={token}\"\n",
    "\n",
    "    table = None\n",
    "    field_value = None\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            time.sleep(1.0)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            table = soup.find(\"table\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            wait = 2**i\n",
    "            print(f\"âš ï¸ Feil ved henting av fotodato ({e}), prÃ¸ver igjen om {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "    if table:\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) >= 2 and cells[0].text.strip() == \"Fotodato\":\n",
    "                field_value = cells[1].text.strip()\n",
    "                field_value = datetime.strptime(field_value, \"%d.%m.%Y\").date()\n",
    "                return field_value\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1517cfdd-9805-4f47-b06c-5f522bae58e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_ortofoto_date(df: DataFrame, token: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Legger til fotodato kolonnen til en DataFrame.\n",
    "    \"\"\"\n",
    "    # Henter bare relevante kolonner\n",
    "    sample_rows = df.select(\"row_hash\", \"bbox_str\").collect()\n",
    "\n",
    "    # Henter fotodato\n",
    "    bbox_date_pairs = [\n",
    "        (row[\"row_hash\"], get_fotodato(row[\"bbox_str\"].replace(\"_\", \",\"), token))\n",
    "        for row in sample_rows\n",
    "    ]\n",
    "\n",
    "    schema = StructType(\n",
    "        [\n",
    "            StructField(\"row_hash\", StringType(), True),\n",
    "            StructField(\"photo_time\", DateType(), True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    bbox_date_df = spark.createDataFrame(bbox_date_pairs, schema)\n",
    "    df_with_date = df.join(bbox_date_df, on=\"row_hash\", how=\"left\")\n",
    "\n",
    "    return df_with_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "136dd677-715a-4a51-87fe-3c6fb99448b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def build_overlap_graph(df: DataFrame) -> DataFrame:\n",
    "    df_with_id = df.withColumn(\"row_id\", F.monotonically_increasing_id())\n",
    "    overlap_df = (\n",
    "        df_with_id.alias(\"a\")\n",
    "        .join(\n",
    "            df_with_id.alias(\"b\"),\n",
    "            F.expr(\n",
    "                \"\"\"\n",
    "                ST_Intersects(\n",
    "                    ST_MakeEnvelope(a.bbox[0], a.bbox[1], a.bbox[2], a.bbox[3]),\n",
    "                    ST_MakeEnvelope(b.bbox[0], b.bbox[1], b.bbox[2], b.bbox[3])\n",
    "                )\n",
    "            \"\"\"\n",
    "            ),\n",
    "        )\n",
    "        .select(\n",
    "            F.col(\"a.lokalid\").alias(\"lokalid_a\"),\n",
    "            F.col(\"b.lokalid\").alias(\"lokalid_b\"),\n",
    "        )\n",
    "    )\n",
    "    return overlap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ed7b94b-8907-496c-9054-5f24e94854ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def connected_components(edges: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Finner sammenhengende komponenter i en graf.\n",
    "    \"\"\"\n",
    "    vertices = (\n",
    "        edges.select(\"src\")\n",
    "        .union(edges.select(\"dst\"))\n",
    "        .distinct()\n",
    "        .withColumn(\"component\", F.col(\"src\"))\n",
    "    )\n",
    "    changed = True\n",
    "    while changed:\n",
    "        propagated = (\n",
    "            edges.alias(\"e\")\n",
    "            .join(vertices.alias(\"v\"), F.col(\"e.src\") == F.col(\"v.src\"))\n",
    "            .select(F.col(\"e.dst\").alias(\"src\"), F.col(\"v.component\"))\n",
    "        )\n",
    "        new_vertices = (\n",
    "            vertices.union(propagated)\n",
    "            .groupBy(\"src\")\n",
    "            .agg(F.min(\"component\").alias(\"component\"))\n",
    "        )\n",
    "        joined = new_vertices.alias(\"n\").join(vertices.alias(\"v\"), \"src\")\n",
    "        changed = (\n",
    "            joined.filter(F.col(\"n.component\") != F.col(\"v.component\")).count() > 0\n",
    "        )\n",
    "        vertices = new_vertices\n",
    "    return vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29378610-4507-47f1-9e66-b310cb273976",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def merge_chain_geometries(chains_with_geom: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    SlÃ¥r sammen polygoner i en linje og returnerer det som en polygon.\n",
    "    \"\"\"\n",
    "    merge_udf = F.udf(merge_polygons, BinaryType())\n",
    "    chains_union = (\n",
    "        chains_with_geom.groupBy(\"component\")\n",
    "        .agg(\n",
    "            F.collect_list(\"geometry\").alias(\"geom_list\"),\n",
    "            F.collect_list(\"lokalid\").alias(\"lokalids\"),\n",
    "        )\n",
    "        .withColumn(\"merged_wkb\", merge_udf(\"geom_list\"))\n",
    "        .withColumn(\"merged_geom\", F.expr(\"ST_GeomFromWKB(merged_wkb)\"))\n",
    "        .withColumn(\"type\", F.lit(\"chain\"))\n",
    "    )\n",
    "    chains_union = make_envelope(chains_union, \"merged_geom\")\n",
    "    chains_union = envelope_to_bboxes(chains_union)\n",
    "    return chains_union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "35ddf5dd-c572-4118-82d8-dbc758742408",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def enrich_output(df: DataFrame, token: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Legger til kolonner med info om bilder, masker og tid.\n",
    "    \"\"\"\n",
    "    df = add_geometry_columns(df)\n",
    "    for dt in [\"image\", \"mask\"]:\n",
    "        sub = SUBDIR[dt]\n",
    "        df = df.withColumn(\n",
    "            f\"{dt}_path\",\n",
    "            F.concat(\n",
    "                F.lit(f\"{BASE_PATH}/{sub}/{dt}_\"), F.col(\"row_hash\"), F.lit(\".png\")\n",
    "            ),\n",
    "        )\n",
    "    df = (\n",
    "        df.withColumn(\"image_wms\", generate_image_url_udf(\"bbox_str\"))\n",
    "        .withColumn(\"image_status\", image_file_exists_udf(\"row_hash\"))\n",
    "        .withColumn(\"mask_status\", mask_file_exists_udf(\"row_hash\"))\n",
    "        .withColumn(\"load_time\", F.current_timestamp())\n",
    "    )\n",
    "    df = add_ortofoto_date(df, token)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd0f7254-730e-4aed-b342-3aae83fcb6ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def merge_polygons(polys):\n",
    "    \"\"\"\n",
    "    SlÃ¥r sammen polygoner fra en liste til en enkelt polygon.\n",
    "    \"\"\"\n",
    "    shapes = [p for p in polys if p is not None]\n",
    "    if not shapes:\n",
    "        return None\n",
    "    merged = unary_union(shapes)\n",
    "    return merged.wkb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "315a21f8-7fcc-4a3f-b6fb-bb0ba978244d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_delta_table(sdf: DataFrame, mode: str = \"merge\") -> None:\n",
    "    \"\"\"\n",
    "    Skriver data til deltatabellen og opdaterer dersom row_hash allerede finnes.\n",
    "    \"\"\"\n",
    "    if mode == \"overwrite\":\n",
    "        sdf.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\n",
    "            \"overwrite\"\n",
    "        ).saveAsTable(silver_table)\n",
    "    else:\n",
    "        from delta.tables import DeltaTable\n",
    "\n",
    "        delta_tbl = DeltaTable.forName(spark, silver_table)\n",
    "\n",
    "        delta_tbl.alias(\"target\").merge(\n",
    "            sdf.alias(\"source\"), condition=\"target.row_hash = source.row_hash\"\n",
    "        ).whenMatchedUpdate(\n",
    "            condition=\"target.load_time < source.load_time OR target.image_path IS NULL\",\n",
    "            set={col: f\"source.{col}\" for col in sdf.columns},\n",
    "        ).whenNotMatchedInsert(\n",
    "            values={col: f\"source.{col}\" for col in sdf.columns}\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e7e197a-f2ac-4196-9699-997217c7f438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adjusted_bbox_schema = StructType(\n",
    "    [\n",
    "        StructField(\"bbox\", ArrayType(DoubleType())),\n",
    "        StructField(\"bbox_str\", StringType()),\n",
    "    ]\n",
    ")\n",
    "adjusted_bbox_udf = F.udf(\n",
    "    lambda envelope: random_adjusted_bbox_centered(envelope), adjusted_bbox_schema\n",
    ")\n",
    "generate_image_url_udf = F.udf(generate_image_url, StringType())\n",
    "image_file_exists_udf = F.udf(image_file_exists, StringType())\n",
    "mask_file_exists_udf = F.udf(mask_file_exists, StringType())\n",
    "merge_udf = F.udf(merge_polygons, BinaryType())\n",
    "\n",
    "df = read_table_to_wkt()\n",
    "df = make_envelope(df, \"geometry\")\n",
    "df = envelope_to_bboxes(df)\n",
    "\n",
    "edges = (\n",
    "    build_overlap_graph(df)\n",
    "    .select(\"lokalid_a\", \"lokalid_b\")\n",
    "    .withColumnRenamed(\"lokalid_a\", \"src\")\n",
    "    .withColumnRenamed(\"lokalid_b\", \"dst\")\n",
    ")\n",
    "vertices = connected_components(edges)\n",
    "\n",
    "chains = vertices.groupBy(\"component\").agg(F.collect_list(\"src\").alias(\"lokalids\"))\n",
    "chains_filtered = chains.filter(F.size(\"lokalids\") > 1)\n",
    "chains_exploded = chains_filtered.withColumn(\"lokalid\", F.explode(\"lokalids\"))\n",
    "chains_with_geom = chains_exploded.join(df, \"lokalid\", \"inner\").select(\n",
    "    \"component\", \"lokalid\", \"geometry\"\n",
    ")\n",
    "\n",
    "chains_union = merge_chain_geometries(chains_with_geom)\n",
    "\n",
    "chain_ids = chains_filtered.select(F.explode(\"lokalids\").alias(\"lokalid\"))\n",
    "singletons = (\n",
    "    df.join(chain_ids, \"lokalid\", \"left_anti\")\n",
    "    .select(\"lokalid\", \"geometry\", \"envelope\", \"bbox\")\n",
    "    .withColumn(\"merged_geom\", F.col(\"geometry\"))\n",
    "    .withColumn(\"lokalids\", F.array(\"lokalid\"))\n",
    "    .withColumn(\"type\", F.lit(\"singleton\"))\n",
    ")\n",
    "\n",
    "new_df = chains_union.select(\n",
    "    \"component\", \"lokalids\", \"merged_geom\", \"envelope\", \"bbox\", \"type\"\n",
    ").unionByName(\n",
    "    singletons.select(\n",
    "        F.col(\"lokalid\").alias(\"component\"),\n",
    "        \"lokalids\",\n",
    "        \"merged_geom\",\n",
    "        \"envelope\",\n",
    "        \"bbox\",\n",
    "        \"type\",\n",
    "    )\n",
    ")\n",
    "\n",
    "df = (\n",
    "    new_df.withColumn(\n",
    "        \"row_hash\", F.sha2(F.concat_ws(\"||\", F.col(\"lokalids\"), F.col(\"bbox\")), 256)\n",
    "    )\n",
    "    .withColumnRenamed(\"merged_geom\", \"geometry\")\n",
    "    .drop(\"component\")\n",
    ")\n",
    "df = enrich_output(df, token)\n",
    "\n",
    "df = df.withColumn(\"geometry\", F.expr(\"ST_AsBinary(geometry)\"))\n",
    "df = df.withColumn(\"Polygons\", F.expr(\"ST_AsBinary(Polygons)\"))\n",
    "write_delta_table(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "helipads_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
