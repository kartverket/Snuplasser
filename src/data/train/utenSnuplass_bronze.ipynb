{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8fb71f55-f7f7-4d04-90e6-15a3b1cc8dad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "from pyspark.sql.functions import *\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    "    TimestampType,\n",
    "    IntegerType,\n",
    ")\n",
    "\n",
    "from src.data.data_utils import write_delta_table, write_to_delta_table\n",
    "from src.data.geometry_utils import to_wkt_2d\n",
    "from src.data.log_utils import check_for_new_gdbs, log_processed_gdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8253ecf-e402-4da3-a842-0c871d473027",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "gcs_landing_zone = \"/Volumes/land_auto-gen-kart_dev/external_dev/landing_zone/\"\n",
    "catalog_dev = \"`land_auto-gen-kart_dev`\"\n",
    "schema_dev = \"dl_bildesegmentering\"\n",
    "spark.sql(f\"USE CATALOG {catalog_dev}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_dev}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_dev}\")\n",
    "log_table = \"logs_processed_gdbs_utensnuplass\"\n",
    "bronze_table = \"utensnuplass_bronze\"\n",
    "layer = \"ikke_snuplass\"\n",
    "\n",
    "layer_crs = 32633"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "777bce9a-6c17-4746-afca-06516ae2e125",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {bronze_table} (\n",
    "   geometry STRING,\n",
    "   ingest_time TIMESTAMP,\n",
    "   source_file STRING,\n",
    "   source_layer STRING,\n",
    "   row_hash STRING\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42f165ba-c05b-4e17-ae4d-a171ad53b7d3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {log_table} (\n",
    "  gdb_name STRING,\n",
    "  processed_time TIMESTAMP,\n",
    "  num_inserted INT,\n",
    "  num_updated INT,\n",
    "  num_deleted INT\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc0d81fd-e073-4b32-9e3a-172c874d24cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_to_sdf(gdb_path: str, gdb_name: str, layer: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Returnerer en spark dataframe med data fra deltatabellen.\n",
    "    \"\"\"\n",
    "    gdf = (\n",
    "        gpd.read_file(gdb_path, layer=layer).set_crs(\"EPSG:25833\").to_crs(\"EPSG:25833\")\n",
    "    )\n",
    "    gdf[\"wkt_geometry\"] = gdf[\"geometry\"].apply(to_wkt_2d)\n",
    "    gdf = gdf.drop(columns=[\"geometry\"])\n",
    "\n",
    "    sdf = spark.createDataFrame(gdf)\n",
    "    sdf = sdf.withColumnRenamed(\"wkt_geometry\", \"geometry\")\n",
    "    sdf = (\n",
    "        sdf.withColumn(\"ingest_time\", current_timestamp())\n",
    "        .withColumn(\"source_file\", lit(gdb_name))\n",
    "        .withColumn(\"source_layer\", lit(layer))\n",
    "        .withColumn(\"row_hash\", sha2(concat_ws(\"||\", *sdf.columns), 256))\n",
    "    )\n",
    "\n",
    "    target_cols = DeltaTable.forName(spark, bronze_table).toDF().columns\n",
    "    sdf = sdf.select([c for c in sdf.columns if c in target_cols])\n",
    "    sdf = sdf.dropDuplicates([\"row_hash\"])\n",
    "\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f939ed85-3060-4367-a708-c0636a27d597",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Finner nye geodatabaser og skriver til deltatabellen.\n",
    "    \"\"\"\n",
    "    gdbs = check_for_new_gdbs(gcs_landing_zone, log_table, \"Snuplasser\")\n",
    "    for gdb in gdbs:\n",
    "        gdb_name = gdb.rstrip(\"/\").split(\"/\")[-1]\n",
    "        gdb_path = gdb.removeprefix(\"dbfs:\")\n",
    "\n",
    "        sdf = write_to_sdf(gdb_path, gdb_name, layer)\n",
    "        write_to_delta_table(sdf, gdb_name, bronze_table, log_table, \"row_hash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577ee55e-f3de-4ba8-a93b-2f92327e70ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utenSnuplass_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
