{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fae414af-aa12-4f87-ac4c-c30924131787",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import (\n",
    "    ArrayType,\n",
    "    DoubleType,\n",
    "    StringType,\n",
    "    StructType,\n",
    "    StructField,\n",
    "    DateType,\n",
    ")\n",
    "from delta.tables import DeltaTable\n",
    "from sedona.spark import *\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from datetime import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8ebd42cb-53ce-4e88-918b-b2c60e4523d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_dev = \"`land_topografisk-gdb_dev`\"\n",
    "schema_dev = \"ai2025\"\n",
    "spark.sql(f\"USE CATALOG {catalog_dev}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {schema_dev}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_dev}\")\n",
    "bronze_table = \"helicopters_bronze\"\n",
    "silver_table = \"helicopters_silver\"\n",
    "\n",
    "BASE_PATH = \"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER\"\n",
    "SUBDIR = {\"image\": \"helicopter_images\", \"mask\": \"helicopter_labels\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2a7d9d1-5c7e-4209-a041-ca79e6378531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "q = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {silver_table} (\n",
    "    lokalid STRING,\n",
    "    geometry BINARY,\n",
    "    oppdateringsdato TIMESTAMP,\n",
    "    ingest_time TIMESTAMP,\n",
    "    bbox ARRAY<DOUBLE>,\n",
    "    Polygons BINARY,\n",
    "    adjusted_struct STRUCT<bbox: ARRAY<DOUBLE>, bbox_str: STRING>,\n",
    "    Adjusted_bbox ARRAY<DOUBLE>,\n",
    "    bbox_str STRING,\n",
    "    image_path STRING,\n",
    "    mask_path STRING,\n",
    "    image_wms STRING,\n",
    "    image_status STRING,\n",
    "    mask_status STRING,\n",
    "    load_time TIMESTAMP,\n",
    "    photo_time TIMESTAMP\n",
    ") USING DELTA\n",
    "\"\"\"\n",
    "spark.sql(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "034fb654-9c05-4754-af38-fc32b6dbad04",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def read_table_to_wkt():\n",
    "    \"\"\"\n",
    "    Leser polygonene fra bronsetabellen og returnerer dem som en GeoDataFrame med WKT geometri.\n",
    "    \"\"\"\n",
    "    df_bronze = spark.read.table(bronze_table).withColumn(\n",
    "        \"geometry\", F.expr(\"ST_GeomFromWKB(geometry)\")\n",
    "    )\n",
    "    df = (\n",
    "        df_bronze.withColumn(\"_geom_srid\", F.expr(\"ST_SetSRID(geometry, 4326)\"))\n",
    "        .withColumn(\"geometry\", F.expr(\"ST_Force2D(ST_Transform(_geom_srid, 'EPSG:25833'))\"))\n",
    "        .select(\"lokalid\", \"geometry\", \"ingest_time\", \"oppdateringsdato\")\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "541cacc0-601d-406d-b9f1-b1e7bf9bc152",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_envelope(df: DataFrame) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Lager en minimal boks rundt polygonene.\n",
    "    \"\"\"\n",
    "    return df.withColumn(\"envelope\", F.expr(\"ST_Envelope(geometry)\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12fca104-5f0c-4005-ae40-64f86c5abb89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def random_adjusted_bbox_centered(\n",
    "    envelope: list, bbox_size: int = 128, max_offset: float = 50\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Genererer en tilfeldig justert boks rundt polygonen med en maksimal avstand fra sentrum.\n",
    "    \"\"\"\n",
    "    xmin, ymin, xmax, ymax = envelope\n",
    "    poly_width = xmax - xmin\n",
    "    poly_height = ymax - ymin\n",
    "\n",
    "    if poly_width > bbox_size or poly_height > bbox_size:\n",
    "        print(\"OBS: polygon er stÃ¸rre enn bbox\")\n",
    "        max_offset = 0\n",
    "\n",
    "    half_size = bbox_size / 2\n",
    "\n",
    "    center_x = (xmin + xmax) / 2 + random.uniform(-max_offset, max_offset)\n",
    "    center_y = (ymin + ymax) / 2 + random.uniform(-max_offset, max_offset)\n",
    "\n",
    "    adjusted_xmin = center_x - half_size\n",
    "    adjusted_xmax = center_x + half_size\n",
    "    adjusted_ymin = center_y - half_size\n",
    "    adjusted_ymax = center_y + half_size\n",
    "\n",
    "    bbox = [adjusted_xmin, adjusted_ymin, adjusted_xmax, adjusted_ymax]\n",
    "    bbox_str = \"_\".join(f\"{v:.6f}\" for v in bbox)\n",
    "    return bbox, bbox_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fcff5e74-7ac1-4da1-9a11-765f7a540cc0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def make_bbox(df: DataFrame, column_name: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Lager en boks rundt polygonen med en fast avstand fra sentrum.\n",
    "    \"\"\"\n",
    "    df = df.withColumn(\n",
    "        \"bbox\",\n",
    "        F.expr(\n",
    "            f\"\"\"\n",
    "        array(\n",
    "            ST_X(ST_Centroid({column_name})) - 256,\n",
    "            ST_Y(ST_Centroid({column_name})) - 256,\n",
    "            ST_X(ST_Centroid({column_name})) + 256,\n",
    "            ST_Y(ST_Centroid({column_name})) + 256\n",
    "        )\n",
    "        \"\"\"\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    df = (\n",
    "        df.withColumn(\n",
    "            \"Polygons\", F.expr(\"ST_MakeEnvelope(bbox[0], bbox[1], bbox[2], bbox[3])\")\n",
    "        )\n",
    "        .withColumn(\"adjusted_struct\", adjusted_bbox_udf(F.col(\"bbox\")))\n",
    "        .withColumn(\"Adjusted_bbox\", F.col(\"adjusted_struct.bbox\"))\n",
    "        .withColumn(\"bbox_str\", F.col(\"adjusted_struct.bbox_str\"))\n",
    "        .drop(column_name)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13f94661-9628-453d-b331-dd560363e836",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def generate_image_url(bbox_str: str) -> str:\n",
    "    \"\"\"\n",
    "    Genererer en URL for image-bilde basert pÃ¥ bbox_str.\n",
    "    \"\"\"\n",
    "    width, height = [512, 512]\n",
    "    return (\n",
    "        f\"https://wms.geonorge.no/skwms1/wms.nib?VERSION=1.3.0\"\n",
    "        f\"&service=WMS&request=GetMap&Format=image/png&\"\n",
    "        f\"GetFeatureInfo=text/plain&CRS=EPSG:25833&Layers=ortofoto&\"\n",
    "        f\"BBox={bbox_str}&width={width}&height={height}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def image_file_exists(id: str) -> str:\n",
    "    \"\"\"\n",
    "    Sjekker om bildet med gitt ID er lastet ned.\n",
    "    \"\"\"\n",
    "    path = f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/helicopter_images/image_{id}.png\"\n",
    "    return \"DOWNLOADED\" if os.path.exists(path) else \"PENDING\"\n",
    "\n",
    "\n",
    "def mask_file_exists(id: str) -> str:\n",
    "    \"\"\"\n",
    "    Sjekker om masken med gitt ID er generert.\n",
    "    \"\"\"\n",
    "    path = f\"/Volumes/land_topografisk-gdb_dev/external_dev/static_data/DL_SNUPLASSER/helicopter_labels/mask_{id}.png\"\n",
    "    return \"GENERATED\" if os.path.exists(path) else \"PENDING\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad68254d-ce96-405f-a054-14da16b43503",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "BRUKERID = os.getenv(\"GEONORGE_BRUKERID\")\n",
    "PASSORD = os.getenv(\"GEONORGE_PASSORD\")\n",
    "\n",
    "\n",
    "def get_token():\n",
    "    \"\"\"\n",
    "    Henter token fra GeoNorge og returnerer det.\n",
    "    \"\"\"\n",
    "    url = (\n",
    "        f\"https://baat.geonorge.no/skbaatts/req?brukerid={BRUKERID}\"\n",
    "        f\"&passord={PASSORD}&tjenesteid=wms.nib&retformat=s\"\n",
    "    )\n",
    "    raw_token = requests.get(url).text.strip(\"`\")\n",
    "    return raw_token\n",
    "\n",
    "\n",
    "token = get_token()\n",
    "token_start_time = time.time()\n",
    "token_lifetime = 55 * 60\n",
    "\n",
    "\n",
    "def refresh_token_if_needed():\n",
    "    \"\"\"\n",
    "    Henter ny token om den gamle er utlÃ¸pt.\n",
    "    \"\"\"\n",
    "    global token, token_start_time\n",
    "    if time.time() - token_start_time > token_lifetime:\n",
    "        print(\"ðŸ”„ Fornyer token...\")\n",
    "        token = get_token()\n",
    "        token_start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f9c9114-4a3a-449a-8cc9-a451b92a4032",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_fotodato(bbox: str, token: str, max_retries=10):\n",
    "    \"\"\"\n",
    "    Henter fotodato for en bbox.\n",
    "    \"\"\"\n",
    "    url = f\"https://wms.geonorge.no/skwms1/wms.nib?SERVICE=WMS&VERSION=1.3.0&REQUEST=GetFeatureInfo&CRS=EPSG:25833&BBOX={bbox}&WIDTH=512&HEIGHT=512&LAYERS=ortofoto&QUERY_LAYERS=ortofoto&INFO_FORMAT=text/html&I=256&J=256&TICKET={token}\"\n",
    "\n",
    "    table = None\n",
    "    field_value = None\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            response = requests.get(url, timeout=10)\n",
    "            time.sleep(1.0)\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            table = soup.find(\"table\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            wait = 2**i\n",
    "            print(f\"âš ï¸ Feil ved henting av fotodato ({e}), prÃ¸ver igjen om {wait}s...\")\n",
    "            time.sleep(wait)\n",
    "\n",
    "    if table:\n",
    "        rows = table.find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            cells = row.find_all(\"td\")\n",
    "            if len(cells) >= 2 and cells[0].text.strip() == \"Fotodato\":\n",
    "                field_value = cells[1].text.strip()\n",
    "                field_value = datetime.strptime(field_value, \"%d.%m.%Y\").date()\n",
    "                return field_value\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1517cfdd-9805-4f47-b06c-5f522bae58e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def add_ortofoto_date(df: DataFrame, token: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Legger til fotodato kolonnen til en DataFrame.\n",
    "    \"\"\"\n",
    "    # Henter bare relevante kolonner\n",
    "    sample_rows = df.select(\"lokalid\", \"bbox_str\").collect()\n",
    "\n",
    "    # Henter fotodato\n",
    "    bbox_date_pairs = [\n",
    "        (row[\"lokalid\"], get_fotodato(row[\"bbox_str\"].replace(\"_\", \",\"), token))\n",
    "        for row in sample_rows\n",
    "    ]\n",
    "\n",
    "    schema = StructType(\n",
    "        [\n",
    "            StructField(\"lokalid\", StringType(), True),\n",
    "            StructField(\"photo_time\", DateType(), True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    bbox_date_df = spark.createDataFrame(bbox_date_pairs, schema)\n",
    "    df_with_date = df.join(bbox_date_df, on=\"lokalid\", how=\"left\")\n",
    "\n",
    "    return df_with_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b048c4f-6518-4255-8e23-ed8f96336cb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def write_delta_table(sdf: DataFrame, mode: str = \"merge\") -> None:\n",
    "    \"\"\"\n",
    "    Skriver data til deltatabellen og opdaterer dersom lokalid allerede finnes.\n",
    "    \"\"\"\n",
    "    if mode == \"overwrite\":\n",
    "        sdf.write.format(\"delta\").option(\"mergeSchema\", \"true\").mode(\n",
    "            \"overwrite\"\n",
    "        ).saveAsTable(silver_table)\n",
    "    else:\n",
    "        from delta.tables import DeltaTable\n",
    "\n",
    "        delta_tbl = DeltaTable.forName(spark, silver_table)\n",
    "\n",
    "        delta_tbl.alias(\"target\").merge(\n",
    "            sdf.alias(\"source\"), condition=\"target.lokalid = source.lokalid\"\n",
    "        ).whenMatchedUpdate(\n",
    "            condition=\"target.load_time < source.load_time OR target.image_path IS NULL\",\n",
    "            set={col: f\"source.{col}\" for col in sdf.columns},\n",
    "        ).whenNotMatchedInsert(\n",
    "            values={col: f\"source.{col}\" for col in sdf.columns}\n",
    "        ).execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e7e197a-f2ac-4196-9699-997217c7f438",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "adjusted_bbox_schema = StructType(\n",
    "    [\n",
    "        StructField(\"bbox\", ArrayType(DoubleType())),\n",
    "        StructField(\"bbox_str\", StringType()),\n",
    "    ]\n",
    ")\n",
    "adjusted_bbox_udf = F.udf(\n",
    "    lambda envelope: random_adjusted_bbox_centered(envelope), adjusted_bbox_schema\n",
    ")\n",
    "generate_image_url_udf = F.udf(generate_image_url, StringType())\n",
    "image_file_exists_udf = F.udf(image_file_exists, StringType())\n",
    "mask_file_exists_udf = F.udf(mask_file_exists, StringType())\n",
    "\n",
    "df = read_table_to_wkt()\n",
    "df = make_envelope(df)\n",
    "df = make_bbox(df, \"envelope\")\n",
    "\n",
    "for dt in [\"image\", \"mask\"]:\n",
    "    sub = SUBDIR[dt]\n",
    "    df = df.withColumn(\n",
    "        f\"{dt}_path\",\n",
    "        F.concat(F.lit(f\"{BASE_PATH}/{sub}/{dt}_\"), F.col(\"lokalid\"), F.lit(\".png\")),\n",
    "    )\n",
    "df = (\n",
    "    df.withColumn(\"image_wms\", generate_image_url_udf(\"Adjusted_bbox\"))\n",
    "    .withColumn(\"image_status\", image_file_exists_udf(\"lokalid\"))\n",
    "    .withColumn(\"mask_status\", mask_file_exists_udf(\"lokalid\"))\n",
    "    .withColumn(\"load_time\", F.current_timestamp())\n",
    ")\n",
    "df = add_ortofoto_date(df, token)\n",
    "\n",
    "df = df.withColumn(\"geometry\", F.expr(\"ST_AsBinary(geometry)\"))\n",
    "df = df.withColumn(\"Polygons\", F.expr(\"ST_AsBinary(Polygons)\"))\n",
    "\n",
    "write_delta_table(df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "helicopters_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
