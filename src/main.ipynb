{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32aa1d5c-990a-4dfb-a664-dea002106b81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Hovedprogram\n",
    "\n",
    "Utfører trening eller prediksjon på spesifikt datasett avhengig av yaml input-fil."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2416e08d-eb4c-43d7-af2a-fa0866d5fbb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Forberedelser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51be04f5-48a2-4651-8a6c-7a69ca58e580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install lightning segmentation_models_pytorch \"pydantic==2.8.0\" \"albumentations==1.4.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af07ffc5-6620-4692-84d0-19c140c2e1da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import mlflow\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pathlib import Path\n",
    "from lightning.pytorch import Trainer\n",
    "from model.model_factory import get_model\n",
    "from utils.logger import get_logger\n",
    "from utils.callbacks import (\n",
    "    get_early_stopping,\n",
    "    get_model_checkpoint,\n",
    "    LogPredictionsCallback,\n",
    "    log_predictions_from_preds,\n",
    ")\n",
    "from data.datamodule import get_datamodule\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab0a4f30-cc1e-4ac9-b297-27c9ac1fafad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Funksjoner og konstanter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49db09eb-3182-43ff-8f7b-59a23476e69f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff24b68f-252d-431a-9a01-fa8989b1d554",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(model_name: str, config: dict):\n",
    "    \"\"\"\n",
    "    Kjører et MLflow-eksperiment med en gitt modell og konfigurasjon.\n",
    "    Argumenter:\n",
    "        model_name: navnet på modellen som skal brukes.\n",
    "        config: konfigurasjonen for modellen og eksperimentet.\n",
    "    \"\"\"\n",
    "    mode = config.get(\"data\", {}).get(\"mode\", \"train\")\n",
    "    print(f\"Kjører {mode}-jobb for modell: {model_name}\")\n",
    "\n",
    "    # Data & modell\n",
    "    datamodule = get_datamodule(config, model_name)\n",
    "    model = get_model(model_name, config)\n",
    "\n",
    "    # Logger & callbacks\n",
    "    logger = get_logger(model_name, config)\n",
    "    es_cb = get_early_stopping(config.get(\"training\", {}))\n",
    "    ckpt_cb = get_model_checkpoint(config.get(\"training\", {}))\n",
    "    log_pred_cfg = config.get(\"log_predictions_callback\", {})\n",
    "    log_pred_cb = LogPredictionsCallback(**log_pred_cfg)\n",
    "\n",
    "    trainer = Trainer(\n",
    "        logger=logger,\n",
    "        max_epochs=config.get(\"training\", {}).get(\"max_epochs\", 1),\n",
    "        accelerator=config.get(\"training\", {}).get(\"accelerator\", \"cpu\"),\n",
    "        devices=config.get(\"training\", {}).get(\"devices\", 1),\n",
    "        precision=config.get(\"training\", {}).get(\"precision\", 32),\n",
    "        callbacks=[ckpt_cb, es_cb, log_pred_cb] if mode == \"train\" else [],\n",
    "        log_every_n_steps=config.get(\"training\", {}).get(\"log_every_n_steps\", 10),\n",
    "        deterministic=True,\n",
    "    )\n",
    "\n",
    "    if mode == \"train\":\n",
    "        # Tren & test\n",
    "        trainer.fit(model, datamodule=datamodule)\n",
    "        trainer.test(model, datamodule=datamodule)\n",
    "\n",
    "        # Last inn beste checkpoint og logg til MLflow\n",
    "        best_ckpt = ckpt_cb.best_model_path\n",
    "        mlflow.set_registry_uri(config.get(\"logging\", {}).get(\"tracking_uri\", \"\"))\n",
    "        with mlflow.start_run(run_id=trainer.logger.run_id):\n",
    "            trained = model.__class__.load_from_checkpoint(\n",
    "                str(best_ckpt), config=config.get(\"model\", {}).get(model_name, {})\n",
    "            )\n",
    "            # Valider igjen for å få metrikker i MLflow\n",
    "            trainer.validate(trained, datamodule=datamodule)\n",
    "            metrics = trainer.callback_metrics\n",
    "            mlflow.log_metrics(\n",
    "                {\n",
    "                    # \"val_acc\":  metrics[\"val_acc\"].item(),\n",
    "                    \"val_dice\": metrics[\"val_dice\"].item(),\n",
    "                    \"val_iou\": metrics[\"val_iou\"].item(),\n",
    "                    \"val_loss\": metrics[\"val_loss\"].item(),\n",
    "                }\n",
    "            )\n",
    "            mlflow.log_artifact(str(best_ckpt), artifact_path=\"best_checkpoint\")\n",
    "            mlflow.pytorch.log_model(\n",
    "                pytorch_model=trained,\n",
    "                artifact_path=\"model\",\n",
    "                registered_model_name=model_name,\n",
    "            )\n",
    "\n",
    "    elif mode == \"predict\":\n",
    "        # Last inn checkpoint for prediksjon\n",
    "        username = spark.sql(\"SELECT current_user()\").collect()[0][0]\n",
    "        experiment_name = f\"/Users/{username}/{model_name}\"\n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "        experiment_path = Path(\n",
    "            f\"/Workspace/Users/{username}/Snuplasser/src/{experiment_id}\"\n",
    "        )\n",
    "\n",
    "        client = MlflowClient()\n",
    "        runs = client.search_runs(\n",
    "            experiment_ids=[experiment_id],\n",
    "            order_by=[\"attributes.start_time DESC\"],\n",
    "            max_results=100,\n",
    "        )\n",
    "\n",
    "        filtered_runs = []\n",
    "        for run in runs:\n",
    "            experiment_folders = [f for f in experiment_path.iterdir() if f.is_dir()]\n",
    "            for folder in experiment_folders:\n",
    "                if run.info.run_id in folder.name:\n",
    "                    filtered_runs.append(run)\n",
    "\n",
    "        if filtered_runs:\n",
    "            newest = filtered_runs[0]\n",
    "        else:\n",
    "            raise ValueError(\"Fant ingen kjøringer i dette eksperimentet\")\n",
    "\n",
    "        ckpt_path = f\"/Workspace/Users/{username}/Snuplasser/src/{experiment_id}/{newest.info.run_id}/checkpoints/best.ckpt\"\n",
    "        trained = model.__class__.load_from_checkpoint(str(ckpt_path))\n",
    "\n",
    "        # Kjør prediksjon\n",
    "        id_field = config.get(\"data\", {}).get(\"predict\", {}).get(\"id_field\", \"row_hash\")\n",
    "        local_save_dir = (\n",
    "            config.get(\"data\", {})\n",
    "            .get(\"predict\", {})\n",
    "            .get(\"local_save_dir\", \"predicted_snuplasser\")\n",
    "        )\n",
    "        preds = trainer.predict(trained, datamodule=datamodule)\n",
    "        log_predictions_from_preds(preds, logger, id_field, local_save_dir)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Ukjent modus: {mode}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b90778fb-95e0-4265-b5b4-2fc04808ca34",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93e1e5c5-efc0-4970-9ede-34c9583cc870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def main(config_path: str):\n",
    "    \"\"\"\n",
    "    Hovedfunksjonen for å kjøre MLflow-eksperimentene.\n",
    "    Argumenter:\n",
    "        config_path: sti til YAML-konfigurasjonen.\n",
    "    \"\"\"\n",
    "    with open(config_path, \"r\") as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(\"Konfig-innhold:\", config.keys())\n",
    "\n",
    "    for name in config.get(\"model_names\", []):\n",
    "        run_experiment(name, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f2f9fe9-348e-487a-befc-abff8b686c77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        \"--config\", type=str, default=\"train_blokkmark.yaml\", help=\"Sti til YAML-konfigurasjon\"\n",
    "    )\n",
    "    args, _ = parser.parse_known_args()\n",
    "    main(args.config)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "main",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
